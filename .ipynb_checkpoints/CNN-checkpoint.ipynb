{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44267828",
   "metadata": {},
   "source": [
    "Trabajo final de Redes Neuronales FIUBA.\n",
    "Modelo basado en ResNet50 para localizar el estado correspondiente a un grupo de 4 imagenes de google street view de entrada con orientacion N,S,E,O dentro de los Estados Unidos.\n",
    "\n",
    "Articulos relevantes:\n",
    "https://arxiv.org/pdf/1810.03077.pdf\n",
    "https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6417592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_data as data\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from matplotlib import cm\n",
    "from operator import concat\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import resnet50\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a940c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparo los datos con el codigo del github. Obtengo una lista de tuplas con las 4 imagenes de cada posicion geografica\n",
    "# Se guardan unicamente las posiciones para las cuales exiten las 4 direcciones. \n",
    "# all_labels contiene los 50 estados. labels es una lista que vincula cada tupla de 4 imagenes con la cadena presente en all_labels\n",
    "\n",
    "data_dir = pathlib.Path(\"50States2k_test\\\\test_data\")\n",
    "files,labels, all_labels = data.read_grouped_filenames_and_labels(\"50States2k_test\\\\test_data\")\n",
    "train_files, train_labels, val_files, val_labels = data.train_val_split(files, labels)\n",
    "# is_training = tf.compat.v1.placeholder(tf.bool, name='is_training')\n",
    "\n",
    "train_data = data.grouped_streetview_dataset(train_files, train_labels, batch_size=32,\n",
    "                                                 augment = True, shuffle = True)\n",
    "val_data = data.grouped_streetview_dataset(val_files, val_labels, batch_size=32,\n",
    "                                               augment = False, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38d2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo el set de entrenamiento en una lista de paths para cada direccion\n",
    "trainNorth = [elemento for elemento,_,_,_ in train_files]\n",
    "trainEast = [elemento for _,elemento,_,_ in train_files]\n",
    "trainSouth = [elemento for _,_,elemento,_ in train_files]\n",
    "trainWest = [elemento for _,_,_,elemento in train_files]\n",
    "\n",
    "# Separo el set de validacion en una lista de paths para cada direccion\n",
    "valNorth = [elemento for elemento,_,_,_ in val_files]\n",
    "valEast = [elemento for _,elemento,_,_ in val_files]\n",
    "valSouth = [elemento for _,_,elemento,_ in val_files]\n",
    "valWest = [elemento for _,_,_,elemento in val_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93497bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(filename, label):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def iterator_from_list(img_list,labels,batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_list,labels))\n",
    "    dataset = dataset.map(_parse_function).batch(batch_size)\n",
    "    return tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "\n",
    "# Creo un iterador sobre el dataset de cada lista\n",
    "it_north = iterator_from_list(trainNorth,train_labels,32)\n",
    "it_south = iterator_from_list(trainSouth,train_labels,32)\n",
    "it_east = iterator_from_list(trainEast,train_labels,32)\n",
    "it_west = iterator_from_list(trainWest,train_labels,32)\n",
    "# Queda ver como pasarle este dato a la red junto con los labels para que sepa contra que aprender.\n",
    "trainNorthTensor, trainNorthLabels = it_north.get_next()\n",
    "print(type((trainNorthTensor,trainNorthLabels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d3d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el modelo de red neuronal pre-entrenado con imagenes de imagenet. Esto tiene sentido? Debería entrenar mi propia red de 0?\n",
    "inputs = tf.keras.Input(shape=(256,256,3))\n",
    "\n",
    "# Para entrenar MI red de 0, quedandome unicamente con la arquitectura de ResNet50 inicializo los pesos en None, asi que arrancan random\n",
    "subNetTrain = resnet50.ResNet50(include_top=False, weights=None, input_tensor=inputs, input_shape=(256,256,3), pooling=max)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "# Para transfer learning tengo que inicializar los pesos con el modelo de imagenet, es mas rapido pero seguro menos preciso\n",
    "subNet = resnet50.ResNet50(include_top=False, weights='imagenet', input_tensor=entrada, input_shape=(256,256,3), pooling=max)\n",
    "flat1 = tf.keras.layers.Flatten()(subNet.layers[-1].output)\n",
    "class1 = tf.keras.layers.Dense(1024, activation='relu')(flat1)\n",
    "output = tf.keras.layers.Dense(10, activation='softmax')(class1)\n",
    "#subNet = tf.keras.models.Model(inputs=subNet.inputs, outputs=output)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "# Reutilizo este modelo para generar la red principal. Este deberia procesar las 4 direcciones, concatenarlas\n",
    "# Pasarlas por una capa fully connected y a partir de esto calcular la perdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98b4a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aparentemente con predict puedo obtener la imagen con los features extraidos y para despues concatenarlas y hacer la ultima capa\n",
    "# north_output = subRedTrain.predict(trainNorthTensor,batch_size=32)\n",
    "# Me da algo de numpy.ndarray. Podría entrenar la red para que aprenda con mis imagenes?\n",
    "def MainNet(inputs, labels):\n",
    "    \n",
    "    north_output = subNetTrain.predict(trainNorthTensor,batch_size=32)\n",
    "    south_output = subNetTrain.predict(trainSouthTensor,batch_size=32)\n",
    "    east_output = subNetTrain.predict(trainEastTensor,batch_size=32)\n",
    "    west_output = subNetTrain.predict(trainWestTensor,batch_size=32)\n",
    "    \n",
    "    x = tf.\n",
    "    \n",
    "    #x = tf.concat((north_output, west_output, south_output, east_output), axis = 1)\n",
    "\n",
    "    #x = fc(x, self.opt.num_classes) # Esto se tendria que poder hacer con tensorflow\n",
    "    \n",
    "    #preds = tf.nn.softmax(x)\n",
    "    \n",
    "    #wd_loss = tf.add_n([ tf.nn.l2_loss(v) for v in tf.trainable_variables() if 'kernel'])*0.0001\n",
    "    #loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=x))\n",
    "    \n",
    "    #return preds, loss + wd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c419f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
