{
 "cells": [
  {
   "cell_type": "raw",
   "id": "602dd777",
   "metadata": {},
   "source": [
    "Trabajo final de Redes Neuronales FIUBA.\n",
    "Modelo basado en ResNet50 para localizar el estado correspondiente a un grupo de 4 imagenes de google street view de entrada con orientacion N,S,E,O dentro de los Estados Unidos.\n",
    "\n",
    "Articulos relevantes:\n",
    "https://arxiv.org/pdf/1810.03077.pdf\n",
    "https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/\n",
    "https://www.analyticsvidhya.com/blog/2021/11/training-neural-network-with-keras-and-basics-of-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef403a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_data as data\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from matplotlib import cm\n",
    "from operator import concat\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import resnet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "530c366a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa75be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path(\"50States2k_test\\\\test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "042940ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparo los datos con el codigo del github. Obtengo una lista de tuplas con las 4 imagenes de cada posicion geografica\n",
    "# Se guardan unicamente las posiciones para las cuales exiten las 4 direcciones. \n",
    "# all_labels contiene los 50 estados. labels es una lista que vincula cada tupla de 4 imagenes con la cadena presente en all_labels\n",
    "\n",
    "files,labels, all_labels = data.read_grouped_filenames_and_labels(\"50States2k_test\\\\test_data\")\n",
    "train_files, train_labels, val_files, val_labels = data.train_val_split(files, labels)\n",
    "# is_training = tf.compat.v1.placeholder(tf.bool, name='is_training')\n",
    "\n",
    "train_data = data.grouped_streetview_dataset(train_files, train_labels, batch_size=32,\n",
    "                                                 augment = True, shuffle = False)\n",
    "val_data = data.grouped_streetview_dataset(val_files, val_labels, batch_size=32,\n",
    "                                               augment = False, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6cb72c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50States2k_test\\test_data\\New Hampshire\\2007_qSd496JCSUky9VSSz4Ghng_90.jpg\n",
      "New Hampshire\n"
     ]
    }
   ],
   "source": [
    "# Separo el set de entrenamiento en una lista de paths para cada direccion\n",
    "trainNorth = [elemento for elemento,_,_,_ in train_files]\n",
    "trainEast = [elemento for _,elemento,_,_ in train_files]\n",
    "trainSouth = [elemento for _,_,elemento,_ in train_files]\n",
    "trainWest = [elemento for _,_,_,elemento in train_files]\n",
    "\n",
    "# Separo el set de validacion en una lista de paths para cada direccion\n",
    "valNorth = [elemento for elemento,_,_,_ in val_files]\n",
    "valEast = [elemento for _,elemento,_,_ in val_files]\n",
    "valSouth = [elemento for _,_,elemento,_ in val_files]\n",
    "valWest = [elemento for _,_,_,elemento in val_files]\n",
    "\n",
    "n = 37\n",
    "print(train_files[n][1])\n",
    "print(all_labels[train_labels[n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bde3a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "(256, 1024, 3)\n",
      "22499\n"
     ]
    }
   ],
   "source": [
    "num = 35\n",
    "n = PIL.Image.open(str(train_files[num][0]))\n",
    "e = PIL.Image.open(str(train_files[num][1]))\n",
    "s = PIL.Image.open(str(train_files[num][2]))\n",
    "o = PIL.Image.open(str(train_files[num][3]))\n",
    "\n",
    "\n",
    "print(np.array(n).shape)\n",
    "nor = np.array(n)\n",
    "sur = np.array(s)\n",
    "est = np.array(e)\n",
    "wes = np.array(o)\n",
    "\n",
    "concatenada = np.concatenate((nor,est,sur,wes),axis=1)\n",
    "print(concatenada.shape)\n",
    "# plt.imshow(concatenada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f454c-58a2-4bfa-baa1-ef11a5d4d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatFiles(files):\n",
    "    qtty = len(files)\n",
    "    imgList = []\n",
    "    \n",
    "    for i in range(qtty):\n",
    "        n = PIL.Image.open(str(files[i][0]))\n",
    "        e = PIL.Image.open(str(files[i][1]))\n",
    "        s = PIL.Image.open(str(files[i][2]))\n",
    "        o = PIL.Image.open(str(files[i][3]))\n",
    "        \n",
    "        nor = np.array(n)\n",
    "        sur = np.array(s)\n",
    "        est = np.array(e)\n",
    "        wes = np.array(o)\n",
    "        \n",
    "        concatImg = np.concatenate((nor,est,sur,wes),axis=1)\n",
    "        imgList.append(concatImg)\n",
    "        \n",
    "    return imgList\n",
    "    \n",
    "concatList = concatFiles(train_files)\n",
    "print(concatList[1].shape)\n",
    "plt.imshow(concatList[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bb74245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "def _parse_function(filename, label):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def iterator_from_list(img_list,labels,batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_list,labels))\n",
    "    dataset = dataset.map(_parse_function).batch(batch_size)\n",
    "    return tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "\n",
    "# Creo un iterador sobre el dataset de cada lista\n",
    "it_north = iterator_from_list(trainNorth,train_labels,32)\n",
    "it_south = iterator_from_list(trainSouth,train_labels,32)\n",
    "it_east = iterator_from_list(trainEast,train_labels,32)\n",
    "it_west = iterator_from_list(trainWest,train_labels,32)\n",
    "# Queda ver como pasarle este dato a la red junto con los labels para que sepa contra que aprender.\n",
    "trainNorthTensor, trainNorthLabels = it_north.get_next()\n",
    "trainSouthTensor, trainSouthLabels = it_south.get_next()\n",
    "trainEastTensor, trainEastLabels = it_east.get_next()\n",
    "trainWestTensor, trainWestLabels = it_west.get_next()\n",
    "print(type((trainNorthTensor,trainNorthLabels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d57e8f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el modelo de red neuronal pre-entrenado con imagenes de imagenet. Esto tiene sentido? Debería entrenar mi propia red de 0?\n",
    "inputs = tf.keras.Input(shape=(256,256,3))\n",
    "\n",
    "# Para entrenar MI red de 0, quedandome unicamente con la arquitectura de ResNet50 inicializo los pesos en None, asi que arrancan random\n",
    "subNetTrain = resnet50.ResNet50(include_top=False, weights=None, input_tensor=inputs, input_shape=(256,256,3), pooling=max)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "# Para transfer learning tengo que inicializar los pesos con el modelo de imagenet, es mas rapido pero seguro menos preciso\n",
    "subNet = resnet50.ResNet50(include_top=False, weights='imagenet', input_tensor=inputs, input_shape=(256,256,3), pooling=max)\n",
    "flat1 = tf.keras.layers.Flatten()(subNet.layers[-1].output)\n",
    "class1 = tf.keras.layers.Dense(1024, activation='relu')(flat1)\n",
    "output = tf.keras.layers.Dense(10, activation='softmax')(class1)\n",
    "#subNet = tf.keras.models.Model(inputs=subNet.inputs, outputs=output)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "# Reutilizo este modelo para generar la red principal. Este deberia procesar las 4 direcciones, concatenarlas\n",
    "# Pasarlas por una capa fully connected y a partir de esto calcular la perdida\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4eff7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aparentemente con predict puedo obtener la imagen con los features extraidos y para despues concatenarlas y hacer la ultima capa\n",
    "# north_output = subRedTrain.predict(trainNorthTensor,batch_size=32)\n",
    "# Me da algo de numpy.ndarray. Podría entrenar la red para que aprenda con mis imagenes?\n",
    "def MainNet(inputs, labels):\n",
    "    \n",
    "    north_output = subNetTrain.predict(trainNorthTensor,batch_size=32)\n",
    "    south_output = subNetTrain.predict(trainSouthTensor,batch_size=32)\n",
    "    east_output = subNetTrain.predict(trainEastTensor,batch_size=32)\n",
    "    west_output = subNetTrain.predict(trainWestTensor,batch_size=32)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate()([north_output,east_output, south_output,west,output])\n",
    "    flat1 = tf.keras.layers.Flatten()(x)\n",
    "    output = tf.keras.layers.Dense(1024, activation='softmax')(flat1)\n",
    "    completa = tf.keras.models.Model(inputs=subNet.inputs, outputs=output) \n",
    "\n",
    "    #x = fc(x, self.opt.num_classes) # Esto se tendria que poder hacer con tensorflow\n",
    "    \n",
    "    #preds = tf.nn.softmax(x)\n",
    "    \n",
    "    #wd_loss = tf.add_n([ tf.nn.l2_loss(v) for v in tf.trainable_variables() if 'kernel'])*0.0001\n",
    "    #loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=x))\n",
    "    \n",
    "    #return preds, loss + wd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cf3ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aparentemente con predict puedo oobtener la imagen con los features extraidos y para despues concatenarlas y hacer la ultima capa\n",
    "north_output = subNet.predict(trainNorthTensor,batch_size=32)\n",
    "\n",
    "# Me da algo de numpy.ndarray. Podría entrenar la red para que aprenda con mis imagenes?\n",
    "north_output = subNetTrain.predict(trainNorthTensor,batch_size=32)\n",
    "south_output = subNetTrain.predict(trainSouthTensor,batch_size=32)\n",
    "east_output = subNetTrain.predict(trainEastTensor,batch_size=32)\n",
    "west_output = subNetTrain.predict(trainWestTensor,batch_size=32)\n",
    "   \n",
    "x = tf.keras.layers.Concatenate()([north_output,east_output, south_output,west_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c9b4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear el modelo a partir de la concatenación de las subredes entrenadas con los datasets correspondientes, concatenar las salidas\n",
    "north_output = subNetTrain.predict(trainNorthTensor,batch_size=32)\n",
    "south_output = subNetTrain.predict(trainSouthTensor,batch_size=32)\n",
    "east_output = subNetTrain.predict(trainEastTensor,batch_size=32)\n",
    "west_output = subNetTrain.predict(trainWestTensor,batch_size=32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "37c557e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[524288,1024] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-662df72ae210>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnorth_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meast_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msouth_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwest_output\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mflat1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcompleta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubNetTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\davil\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_autocast\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\davil\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2657\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint:disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m       \u001b[1;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m       \u001b[1;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\davil\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m         trainable=True)\n\u001b[0m\u001b[0;32m   1186\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[1;32mc:\\users\\davil\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m         caching_device=caching_device)\n\u001b[0m\u001b[0;32m    664\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m       \u001b[1;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    816\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         **kwargs_for_getter)\n\u001b[0m\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\davil\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[0;32m    127\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         shape=shape)\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m                         shape=None):\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m     \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2624\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2625\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2626\u001b[1;33m         shape=shape)\n\u001b[0m\u001b[0;32m   2627\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2628\u001b[0m     return variables.RefVariable(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1611\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m           \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1613\u001b[1;33m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[0;32m   1614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1615\u001b[0m   def _init_from_args(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1738\u001b[0m           \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initializer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1740\u001b[1;33m               \u001b[0minitial_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1741\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\davil\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\initializers\\initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\davil\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\initializers\\initializers_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m    971\u001b[0m       \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m     return op(\n\u001b[1;32m--> 973\u001b[1;33m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[0;32m    974\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m       result = gen_random_ops.random_uniform(\n\u001b[1;32m--> 310\u001b[1;33m           shape, dtype, seed=seed1, seed2=seed2)\n\u001b[0m\u001b[0;32m    311\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mminval_is_zero\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmaxval_is_one\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[0;32m    718\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6940\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6941\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6942\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\davil\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[524288,1024] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:RandomUniform]"
     ]
    }
   ],
   "source": [
    "x = tf.keras.layers.Concatenate()([north_output,east_output, south_output,west_output])\n",
    "flat1 = tf.keras.layers.Flatten()(x)\n",
    "output = tf.keras.layers.Dense(1024, activation='softmax')(flat1)\n",
    "completa = tf.keras.models.Model(inputs=subNetTrain.inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322d97d9",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------\n",
    "---------                                             ---------\n",
    "---------                                             ---------\n",
    "---------                                             ---------\n",
    "---------                                             ---------\n",
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d20c0d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:6\", shape=(None, 256, 256, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# A ver como le quedan los datos de entrada al chabon. \n",
    "# Ellos le pasan images a la red que construyen, y despues a cada subred le pasan images[0],etc.. \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1.0\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Graph().as_default(), tf.compat.v1.Session(config=config) as sess:\n",
    "    it = tf.compat.v1.data.Iterator.from_structure(tf.compat.v1.data.get_output_types(train_data), tf.compat.v1.data.get_output_shapes(train_data))\n",
    "    filenames_op, rgb, images, labels = it.get_next()\n",
    "#     train_init_op = it.make_initializer(train_data)\n",
    "#     val_init_op = it.make_initializer(val_data)  \n",
    "    \n",
    "print((images[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fbf361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset de todas las imagenes, no me sirve porque existen imagenes que no tienen las 4 direcciones\n",
    "# trainDatasetNorth = tf.keras.utils.image_dataset_from_directory(\n",
    "#   \"50States2k_test\\\\test_data\\\\*\\\\*_0.jpg\",\n",
    "#   validation_split=0.2,\n",
    "#   shuffle=False,\n",
    "#   subset=\"training\",\n",
    "#   image_size=(256,256)\n",
    "# )\n",
    "\n",
    "#Pruebo obtener el dataset de otra manera\n",
    "# def getPic(img_path):\n",
    "#     return np.array(Image.open(img_path).convert('RGB').resize((256,256),Image.ANTIALIAS))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fd0c32d",
   "metadata": {},
   "source": [
    "Supuestamente en images tengo tensores de float32 y shape (256,256,3), por que solo 4? Sera por que tengo de cada direccion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "570f2e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esto está al pedo? Podria irse\n",
    "SubNet = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False, weights='imagenet', input_tensor=inputs,\n",
    "    input_shape=(256,256,3), pooling=max\n",
    ")\n",
    "SubNet.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b2e5014",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_13148/1898567409.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\IGNACI~1\\AppData\\Local\\Temp/ipykernel_13148/1898567409.py\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    north_output = modelo.\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# tf.keras.Input(images[0])\n",
    "# Creo el modelo de red neuronal pre-entrenado con imagenes de imagenet. Esto tiene sentido? Debería entrenar mi propia red de 0?\n",
    "entrada = tf.keras.Input(shape=(256,256,3))\n",
    "modelo = resnet50.ResNet50(include_top=False, weights='imagenet', input_tensor=entrada, input_shape=(256,256,3), pooling=max)\n",
    "\n",
    "def MainNet(inputs, labels):\n",
    "\n",
    "    \n",
    "    ResNet50(include_top=False, weights='imagenet', input_tensor=inputs[0],\n",
    "        input_shape=(256,256,3), pooling=max)\n",
    "    west_output = ResNet50(include_top=False, weights='imagenet', input_tensor=inputs[1],\n",
    "        input_shape=(256,256,3), pooling=max)\n",
    "    south_output = ResNet50(include_top=False, weights='imagenet', input_tensor=inputs[2],\n",
    "        input_shape=(256,256,3), pooling=max)\n",
    "    east_output = ResNet50(include_top=False, weights='imagenet', input_tensor=inputs[3],\n",
    "        input_shape=(256,256,3), pooling=max)\n",
    "\n",
    "    x = tf.concat((north_output, west_output, south_output, east_output),\n",
    "                          axis = 1)\n",
    "    x = fc(x, self.opt.num_classes) # Esto se tendria que poder hacer con tensorflow\n",
    "        \n",
    "    preds = tf.nn.softmax(x)\n",
    "        \n",
    "    wd_loss = tf.add_n([ tf.nn.l2_loss(v) for v in tf.trainable_variables()\n",
    "                             if 'kernel'])*0.0001\n",
    "    loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=x))\n",
    "    return preds, loss + wd_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a40e72",
   "metadata": {},
   "source": [
    "El modelo de la Red completa podria ser algo asi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f14cf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(20).reshape(2, 2, 5)\n",
    "print(x)\n",
    "\n",
    "y = np.arange(20, 30).reshape(2, 1, 5)\n",
    "print(y)\n",
    "tf.keras.layers.Concatenate(axis=1)([x, y])\n",
    "tf.Tensor: shape=(2, 3, 5), dtype=int64, numpy=\n",
    "array([[[ 0,  1,  2,  3,  4],\n",
    "        [ 5,  6,  7,  8,  9],\n",
    "        [20, 21, 22, 23, 24]],\n",
    "       [[10, 11, 12, 13, 14],\n",
    "        [15, 16, 17, 18, 19],\n",
    "        [25, 26, 27, 28, 29]]])>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf40308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
