{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9bdcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that implements the variations of ResNet presented in the original paper\n",
    "class Resnet(object):\n",
    "    def __init__(self, opt):\n",
    "        self.use_batchnorm = opt.use_batchnorm\n",
    "        self.block_filters = opt.block_filters\n",
    "        self.block_strides = opt.block_strides\n",
    "        self.block_sizes = opt.block_sizes\n",
    "        self.block = basicblock if opt.block_type == 'basicblock' else bottleneck\n",
    "        self.opt = opt\n",
    "        if opt.preset == '50':\n",
    "            self.block = bottleneck\n",
    "            self.block_filters = [ 256, 512, 1024, 2048 ]\n",
    "            self.block_sizes = [3, 4, 6, 3]\n",
    "            self.block_strides = [ 1, 2, 2, 2 ]\n",
    "        elif opt.preset == '18':\n",
    "            self.block = bottleneck\n",
    "            self.block_filters = [ 64, 128, 256, 512 ]\n",
    "            self.block_sizes = [2, 2, 2, 2]\n",
    "            self.block_strides = [ 1, 2, 2, 2 ]\n",
    "        \n",
    "    def build_net(self, images, labels, is_training):\n",
    "        with tf.variable_scope('block0') as scope:\n",
    "            x = conv(images, 7, 64, 2, name='conv1', use_bias = not self.use_batchnorm)\n",
    "            if self.use_batchnorm:\n",
    "                x = bn(x, is_training)\n",
    "            x = relu(x)\n",
    "            x = maxpool(x, 3, 2)\n",
    "\n",
    "        blockno = 1\n",
    "        for size, filters, stride in zip(self.block_sizes, self.block_filters,\n",
    "                                         self.block_strides):\n",
    "            print('Making basic block {}'.format(blockno))\n",
    "            with tf.variable_scope('block{}'.format(blockno)) as scope:\n",
    "                for i in range(size):\n",
    "                    x = self.block(x, filters, stride if i == 0 else 1,\n",
    "                                   is_training, name='block{}'.format(i+1),\n",
    "                                   use_batchnorm = self.use_batchnorm,\n",
    "                                   use_bias = not self.use_batchnorm)\n",
    "                blockno = blockno + 1\n",
    "\n",
    "        with tf.variable_scope('output'):\n",
    "            x = tf.reduce_mean(x, axis = [1,2])\n",
    "            x = fc(x, self.opt.num_classes)\n",
    "\n",
    "        preds = tf.nn.softmax(x)\n",
    "\n",
    "        wd_loss = tf.add_n([ tf.nn.l2_loss(v) for v in tf.trainable_variables()\n",
    "                             if 'kernel'])*0.0001\n",
    "        loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=x))\n",
    "        return preds, loss + wd_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d4b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiResNet(Resnet):\n",
    "    def build_subnet(self, images, is_training):\n",
    "        with tf.variable_scope('block0') as scope:\n",
    "            x = conv(images, 7, 64, 2, name='conv1', use_bias = not self.use_batchnorm)\n",
    "            if self.use_batchnorm:\n",
    "                x = bn(x, is_training)\n",
    "            x = relu(x)\n",
    "            x = maxpool(x, 3, 2)\n",
    "\n",
    "        blockno = 1\n",
    "        for size, filters, stride in zip(self.block_sizes, self.block_filters,\n",
    "                                         self.block_strides):\n",
    "            print('Making basic block {}'.format(blockno))\n",
    "            with tf.variable_scope('block{}'.format(blockno)) as scope:\n",
    "                for i in range(size):\n",
    "                    x = self.block(x, filters, stride if i == 0 else 1,\n",
    "                                   is_training, name='block{}'.format(i+1),\n",
    "                                   use_batchnorm = self.use_batchnorm,\n",
    "                                   use_bias = not self.use_batchnorm)\n",
    "                blockno = blockno + 1\n",
    "\n",
    "        with tf.variable_scope('output'):\n",
    "            x = tf.reduce_mean(x, axis = [1,2])\n",
    "        return x\n",
    "    def build_net(self, inputs, labels, is_training):\n",
    "        with tf.variable_scope('shared'):\n",
    "            north_output = self.build_subnet(inputs[0], is_training)\n",
    "        with tf.variable_scope('shared', reuse = True):\n",
    "            west_output = self.build_subnet(inputs[1], is_training)\n",
    "        with tf.variable_scope('shared', reuse = True):\n",
    "            south_output = self.build_subnet(inputs[2], is_training)\n",
    "        with tf.variable_scope('shared', reuse = True):\n",
    "            east_output = self.build_subnet(inputs[3], is_training)\n",
    "\n",
    "        with tf.variable_scope('combine'):\n",
    "            x = tf.concat((north_output, west_output, south_output, east_output),\n",
    "                          axis = 1)\n",
    "            x = fc(x, self.opt.num_classes)\n",
    "        \n",
    "        preds = tf.nn.softmax(x)\n",
    "        \n",
    "        wd_loss = tf.add_n([ tf.nn.l2_loss(v) for v in tf.trainable_variables()\n",
    "                             if 'kernel'])*0.0001\n",
    "        loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=x))\n",
    "        return preds, loss + wd_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
